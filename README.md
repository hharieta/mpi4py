# Aproximaci√≥n del n√∫mero PI con el m√©todo de Montecarlo ‚õ∞Ô∏è

![c√≠rculo](assets/circulo_inscrito.jpeg)

## ‚öúÔ∏è Teor√≠a ‚öúÔ∏è

1. Considera un cuadrado de lado 2u, centrado en el origen (0,0). Este cuadrado tiene un √°rea de 4u cuadradas.
2. Dentro de este cuadrado se haya inscrito un c√≠rculo de radio 1u, tambi√©n centrado en el origen. El √°rea de este c√≠rculo es œÄ unidades cuadradas.
3. Genera puntos aleatorios uniformemente distribuidos dentro del cuadrado.
4. Cuenta cu√°ntos de estos puntos est√°n dentro del c√≠rculo inscrito.
5. La raz√≥n entre el n√∫mero de puntos dentro del c√≠rculo y el total de puntos generados se aproxima a la raz√≥n entre el √°rea del c√≠rculo y el √°rea del cuadrado. $ Raz√≥n =  \frac{puntos dentro del c√≠rculo}{puntos totales}$
6. Multiplicando esta raz√≥n por 4, obtenemos una estimaci√≥n de œÄ. $ Raz√≥n \times 4 \approx PI $

## ‚öúÔ∏è Aplicaci√≥n con Interfaz de paso de mensajes (MPI) ‚öúÔ∏è

**MPI** es un est√°ndar de comunicaci√≥n utilizado en programaci√≥n paralela para permitir que procesos en un cl√∫ster se comuniquen entre s√≠ y coordinen su trabajo. MPI se utiliza com√∫nmente en aplicaciones de alto rendimiento y c√≥mputo distribuido.

En Python üêç la biblioteca __mpi4py__ proporciona una interfaz para utilizar MPI en scripts Python


### üß© Caracter√≠sticas 

* **Comunicadores**: En MPI, los procesos se organizan en grupos llamados "comunicadores". Cada comunicador tiene un conjunto espec√≠fico de procesos.
* **Env√≠o/Recepci√≥n de Mensajes**: MPI permite que los procesos se comuniquen enviando y recibiendo mensajes entre s√≠. Los mensajes pueden contener datos, como matrices o valores escalares.
* **Operaciones Colectivas**: MPI admite operaciones colectivas que involucran a todos los procesos en un comunicador. Estas operaciones incluyen difusi√≥n `(Bcast)`, reducci√≥n `(Reduce)`, dispersi√≥n `(Scatter)`, recopilaci√≥n `(Gather)`, entre otras.
* **Inicio/Fin MPI**: Se debe inicializar el entorno MPI y se debe finalizar al final del programa.
* **Proceso Ra√≠z**: En operaciones colectivas como la reducci√≥n, hay un proceso que act√∫a como el "proceso ra√≠z" que coordina la operaci√≥n. En `mpi4py`, se puede especificar el proceso ra√≠z mediante el par√°metro root en las funciones colectivas.
* **Ejecuci√≥n Paralela**: Cuando se ejecuta un programa MPI en un cl√∫ster o en una m√°quina con m√∫ltiples n√∫cleos, cada proceso MPI se ejecuta de manera independiente en su propio espacio de memoria, y la comunicaci√≥n entre procesos se realiza a trav√©s de MPI.

üë®‚Äçüè´ **Ejemplo:**

```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

data = 5
result = comm.reduce(data, op=MPI.SUM, root=0)

if rank == 0:
    print(f"La suma total es: {result}")

``````

para ejecutar el script 

```bash
mpirun --oversubscribe -n 6 python suma.py
```